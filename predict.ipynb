{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import tkinter as tk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Import and Combination\n",
    "os.chdir('C:\\\\Users\\\\bradm\\\\OneDrive\\\\Projects\\\\Hold_Predictor')\n",
    "\n",
    "rest_df = pd.read_csv('Active Students Restrictions.csv') # Restrictions\n",
    "df = pd.read_excel('Active Students By Major.xlsx') # main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "df.rename(columns = {'PersonID':'StudentID'}, inplace = True) # Rename 'PersonID' to 'StudentID' in df\n",
    "rest_df.drop([\"StartTerm1\", \"FirstName\", \"LastName\", \"AcadProgramSchool\",\"AcadProgramDepartment\", \"AcadProgramDescription\", \"AcadProgramStatusCode\", \"AcadProgramStatusDescription\"], axis = 1, inplace=True)\n",
    "df_2 = pd.merge(rest_df, df, on='StudentID', how='right') #join\n",
    "df_2.loc[(df_2.Restriction == 'FSFIN'), 'Restriction'] = 1 # make Restriction 1\n",
    "df_2['Restriction'] = df_2['Restriction'].fillna(0) #Replace nulls with 0\n",
    "\n",
    "# Dropping useless variables\n",
    "df_2 = df_2.drop(['StudentID', 'FirstName', 'MiddleName', 'LastName', 'BirthDate',\n",
    "'Age', 'AlienStatusCode', 'AlienStatusDescription', 'ImmigrationStatusCode', 'ImmigrationStatusDescription', 'PrimaryCitizenshipCode',\n",
    "'PrimaryCitizenshipDescription', 'DenominationDescription', 'Sport', 'MajorDepartment', 'MajorCode', 'MajorDescription', 'AcadProgramCode',\n",
    "'AcadProgramDescription', 'AcadProgramStatusDescription', 'AnticipatedCompletionDate', 'EnrollStatusCode', 'EnrollStatusDescription', 'CatalogCode', \n",
    "'StartTerm', 'LastTermRegistered', 'AddressLine1', 'AddressLine2', 'City', 'ZipCode', 'CountryCode', 'CountryName', 'BusinessPhone', 'HomePhone',\n",
    "'MobilePhone', 'PersonalEmail', 'CampusEmail', 'AdvisorName', 'ProgramAdvised', 'RestrictionDescription','HoldStartDate', 'Textbox14', 'Textbox30',\n",
    "'Textbox38', 'Textbox42', 'PrivacyCode', 'PrivacyCode', 'PrivacyCodeDescription', 'AcadLevelCode', 'EthnicGroupDescription', 'TermRegCreds',\n",
    "'OneTermPriorRegCreds', 'TwoTermsPriorRegCreds', 'ThreeTermsPriorRegCreds'], axis = 1)\n",
    "\n",
    "# Categorize variables\n",
    "df_2['Gender'] = df_2.Gender.astype('category')\n",
    "df_2['DenominationCode'] = df_2.DenominationCode.astype('category')\n",
    "df_2['ClassCode'] = df_2.ClassCode.astype('category')\n",
    "df_2['MajorSchool'] = df_2.MajorSchool.astype('category')\n",
    "df_2['AcadProgramStatusCode'] = df_2.AcadProgramStatusCode.astype('category')\n",
    "df_2['AdmitStatusDescription'] = df_2.AdmitStatusDescription.astype('category')\n",
    "df_2['StateCode'] = df_2.StateCode.astype('category')\n",
    "df_2['UGFreshmanTransfer'] = df_2.UGFreshmanTransfer.astype('category')\n",
    "\n",
    "# Create Dummy Variables\n",
    "df_2 = pd.get_dummies(df_2, drop_first=True)\n",
    "\n",
    "# Fill remaining NaN with zero\n",
    "df_2 = df_2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Data Prep\n",
    "X = df_2.drop(['Restriction'], axis = 1)\n",
    "y = df_2.Restriction\n",
    "\n",
    "# Normalize the Data\n",
    "scaler = StandardScaler()\n",
    "Xn = scaler.fit_transform(X)\n",
    "\n",
    "# Training/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size =.3,\n",
    "                                                    random_state=1234, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Decision Tree\n",
      " [[  41  134]\n",
      " [ 124 1174]]\n",
      "\n",
      "Classification Report for Decision Tree\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      1298\n",
      "           1       0.25      0.23      0.24       175\n",
      "\n",
      "    accuracy                           0.82      1473\n",
      "   macro avg       0.57      0.57      0.57      1473\n",
      "weighted avg       0.82      0.82      0.82      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree \n",
    "\n",
    "# Create a model (object) for classification\n",
    "dtm = DecisionTreeClassifier(random_state=5678)\n",
    "dtm.fit(X_train, y_train)\n",
    "y_pred_dtm = dtm.predict(X_test)\n",
    "\n",
    "# Classification Report\n",
    "cm_dtm = metrics.confusion_matrix(y_test,y_pred_dtm, labels=[1,0])\n",
    "print('\\nConfusion Matrix for Decision Tree\\n',cm_dtm)\n",
    "print('\\nClassification Report for Decision Tree\\n')\n",
    "print(metrics.classification_report(y_test,y_pred_dtm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Random Forest\n",
      " [[  23  152]\n",
      " [  17 1281]]\n",
      "\n",
      "Classification Report for Random Forest\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      1298\n",
      "           1       0.57      0.13      0.21       175\n",
      "\n",
      "    accuracy                           0.89      1473\n",
      "   macro avg       0.73      0.56      0.58      1473\n",
      "weighted avg       0.86      0.89      0.85      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rfcm = RandomForestClassifier(random_state=5678)\n",
    "rfcm.fit(X_train, y_train)\n",
    "y_pred_rfcm = rfcm.predict(X_test)\n",
    "\n",
    "# Classification Report\n",
    "cm_rfcm = metrics.confusion_matrix(y_test,y_pred_rfcm, labels=[1,0])\n",
    "print('\\nConfusion Matrix for Random Forest\\n',cm_rfcm)\n",
    "print('\\nClassification Report for Random Forest\\n')\n",
    "print(metrics.classification_report(y_test,y_pred_rfcm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Gradient Boost\n",
      " [[   9  166]\n",
      " [   8 1290]]\n",
      "\n",
      "Classification Report for Gradient Boost\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      1298\n",
      "           1       0.53      0.05      0.09       175\n",
      "\n",
      "    accuracy                           0.88      1473\n",
      "   macro avg       0.71      0.52      0.52      1473\n",
      "weighted avg       0.84      0.88      0.84      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost\n",
    "gbmc = GradientBoostingClassifier()\n",
    "gbmc.fit(X_train, y_train)\n",
    "y_pred_gbmc = gbmc.predict(X_test)\n",
    "\n",
    "# Classification Report\n",
    "cm_gbmc = metrics.confusion_matrix(y_test,y_pred_gbmc, labels=[1,0])\n",
    "print('\\nConfusion Matrix for Gradient Boost\\n',cm_gbmc)\n",
    "print('\\nClassification Report for Gradient Boost\\n')\n",
    "print(metrics.classification_report(y_test,y_pred_gbmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Neural Network\n",
      " [[   8  167]\n",
      " [  23 1275]]\n",
      "\n",
      "Classification Report for Neural Network\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      1298\n",
      "           1       0.26      0.05      0.08       175\n",
      "\n",
      "    accuracy                           0.87      1473\n",
      "   macro avg       0.57      0.51      0.50      1473\n",
      "weighted avg       0.81      0.87      0.83      1473\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bradm\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Classifier\n",
    "nnm = MLPClassifier(activation='relu', solver='adam', max_iter=200)\n",
    "nnm.fit(X_train, y_train)\n",
    "y_pred_nnm = nnm.predict(X_test)\n",
    "\n",
    "# Classification Report\n",
    "cm_nnm = metrics.confusion_matrix(y_test,y_pred_nnm, labels=[1,0])\n",
    "print('\\nConfusion Matrix for Neural Network\\n',cm_nnm)\n",
    "print('\\nClassification Report for Neural Network\\n')\n",
    "print(metrics.classification_report(y_test,y_pred_nnm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 70}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Grid Search for Parameters\n",
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "CV_dt = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=tree_para, cv= 5, scoring='recall')\n",
    "CV_dt.fit(X_train, y_train)\n",
    "\n",
    "# Best Params\n",
    "CV_dt.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Decision Tree\n",
      " [[  49  126]\n",
      " [ 124 1174]]\n",
      "\n",
      "Classification Report for Decision Tree\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      1298\n",
      "           1       0.28      0.28      0.28       175\n",
      "\n",
      "    accuracy                           0.83      1473\n",
      "   macro avg       0.59      0.59      0.59      1473\n",
      "weighted avg       0.83      0.83      0.83      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with Best Parameters\n",
    "# Create a model (object) for classification\n",
    "dtm2 = DecisionTreeClassifier(random_state=5678, criterion='gini', max_depth=30)\n",
    "dtm2.fit(X_train, y_train)\n",
    "y_pred_dtm2 = dtm2.predict(X_test)\n",
    "\n",
    "# Build a confusion matrix and show the Classification Report\n",
    "cm_dtm2 = metrics.confusion_matrix(y_test,y_pred_dtm2, labels=[1,0])\n",
    "print('\\nConfusion Matrix for Decision Tree\\n',cm_dtm2)\n",
    "print('\\nClassification Report for Decision Tree\\n')\n",
    "print(metrics.classification_report(y_test,y_pred_dtm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48c958691d74d993f949ac4d13b853675f5feb4362a9d12e667fe0b93892fc45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
